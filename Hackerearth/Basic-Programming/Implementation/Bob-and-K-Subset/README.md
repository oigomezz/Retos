# [Bob and K-Subset][link]

You are given an array a of size n consisting of integers. Now, you need to find the number of distinct integers x, such that there exists a sequence of distinct indices i1 < i2 < ... < im, 1 <= m <= k and a[i1] or a[i2] or ... or a[im] = x

## Input format

- First line of the each input will contain two space seperated integers n and k denoting the size of the array and maximum size of the subset, respectively.
- Next line will contain n spaced integers denoting elements of the array.

## Output format

Output will consists of a single integer denoting the number of unique integers that can be formed by taking Bitwise OR of every subset of size less than or equal to k.

[link]: https://www.hackerearth.com/practice/basic-programming/implementation/basics-of-implementation/practice-problems/algorithm/bob-and-subset-23f0729c/
